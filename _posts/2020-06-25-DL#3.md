---
layout: post
title: ' [딥러닝] #3 CNN '
category : [School]
tag: [딥러닝]
---

# CNN (Convolution Neural Network) 

![1](https://i.imgur.com/oPZZv3O.png)   

input -> Convolutional layer -> Pooling -> Convolutional -> Pooling 반복 -> 마지막 Fully connected layer -> 예측 

# 왜 CNN 인가? 

## 기존 딥러닝의 단점 - Multi Layer Perception  

![2](https://i.imgur.com/l0d7kFm.png)

조금만 모양이 달라져도 아예 다른 이미지로 인식하는 단점 
그래서 학습 데이터가 많아야 하는데, 그러면 시간이 너무 오래 걸림   

2차원 데이터를 1차원 데이터로 변경하기 때문에 학습이 제대로 되더라도 같은 이미지로 인식 못함   
학습은 되었으나 테스트에서는 이미지 인식 못하는 **Overfitting** 문제 발생  

# CNN 개념 

CNN 은 인간의 시각 정보 처리방식을 흉내내서 2차원에서 바로 특징을 뽑아냄     
-> **이미지 인식에 탁월한 성능**

구성 단계 

**Feature Extraction** 특징탐색 

1. Convolution : 특징 추출, filter 가 모델의 정확도 결정   

2. Pooling : 만들어진 특징 탐색 영역에서 가장 큰 값만 추출해서 데이터 공간 축소    

앞의 두 단계 계속해서 반복 


**Classification** 해당 이미지의 특성 결론짓기 

3. Fully connected layer 로 받아서 1차원으로 길게 나열   

4. Softmax : 주어진 이미지가 특정 클래스에 들어가는지 가중치를 기준으로 분류 (ReLU도 많이 사용) 


## Feature extraction

* **커널**이라는 2차원 행렬을 이동시키면서 이미지의 특징을 찾아냄 (인풋 이미지 사이즈에 따라 달라짐)    

* 수직커널과 수평커널이 있고, 커널과 이미지가 몇 번 겹치는지 계산함   

* 컬러 커널이 아니라 숫자 넘버컬러 사용 (흑백 안에서 0-255 사용)   

* 커널이 계속 이동하면서 계산 -> **특징탐색영역(Feature map)** 으로 나열됨    

* 커널의 숫자가 **가중치**가 됨 

* ReLu [가중치*입력값 + 편향] = Output 


## Filter Kernel 

필터와 커널은 다름.  
컬러 이미지가 있을 경우 세개의 채널이 들어가 있음.  
특징을 찾아낸다면    
필터는 한개의 필터만 필요함    
컬러이미지는 각 이미지에서 돌아다니는 커널이 따로 필요함 -> 커널은 3개 필요       

커널 3개의 값들은 하나에 합쳐서 Feature map 으로 만들어지는데 거기에 bias 더해서 아웃풋으로 저장됨.   


# Tensorflow CNN 

![2](https://i.imgur.com/lvBhJO9.png)

## 모듈 임포트
 
```
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import datasets 
```

## Model 

```
input_shape = (28, 28, 1) # 28*28에 흑백 
num_classes = 10 # 0-9까지 10개 클래스 
learning_rate = 0.001 # 이동 경사 (너무 작게주면 무한루프 -> 0.001 로 시작하는게 좋음) 
```

32 = 배치사이즈   
3*3 = 커널사이즈    
**패딩 Same**  
    
피처맵은 입력데이터보다 작아짐.      
그래서 커널이 이동할 수 있도록 입력데이터랑 똑같은 사이즈를 유지하되 0으로 채워넣음       

## Feature Extraction 
```
inputs = layers.Input(input_shape)
net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)
net = layers.Activation('relu')(net)
net = layers.Conv2D(32, (3, 3), padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPooling2D(pool_size=(2, 2))(net) # 피처맵의 최댓값을 잡는 방법 
net = layers.Dropout(0.5)(net)

net = layers.Conv2D(64, (3, 3), padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.Conv2D(64, (3, 3), padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPooling2D(pool_size=(2, 2))(net)
net = layers.Dropout(0.5)(net) # 드랍아웃 : 너무 많은 레이어는 오버피팅 위험 있음 
```

**Maxpooling**    
최댓값만 뽑아내기   
![3](https://i.imgur.com/sY5o99R.png)


**Dropout**    
너무 많은 레이어로 인한 오버피팅 위험 방지



## Classification 

```
net = layers.Flatten()(net) # 1차원으로 변형 
net = layers.Dense(512)(net) # 1대1 대응 
net = layers.Activation('relu')(net)
net = layers.Dropout(0.5)(net) # 드랍아웃 
net = layers.Dense(num_classes)(net)
net = layers.Activation('softmax')(net) # 들어오는 값의 확률을 따져서 어떤 클래스에 들어갈지 분류  

model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')
```


**Flatten**    
Feature map 을 flat 하게 바꿔서 dense 에 배치할 수 있게 함   


## Compile 
```
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),
              loss='sparse_categorical_crossentropy', #binary는 두개일때만, 아닐때는 categorical
              metrics=['accuracy'])
```
**loss** : loss 최소화    
**metrics=['accuracy'])** : 정확도 예측   


## Preprocess 


x 는 이미지, y는 라벨 데이터   

```
(train_x, train_y), (test_x, test_y) = datasets.mnist.load_data()
train_x = train_x[..., tf.newaxis] # tensor 에 들어갈려면 뒤에 채널 차원 추가해야함 
test_x = test_x[..., tf.newaxis]
train_x = train_x / 255. # 값이 너무 크면 리스케일링 하는게 좋음 
test_x = test_x / 255.
```

## Training 


```
num_epochs = 1   # 한 번에 나오는 라인 갯수   
batch_size = 64  # 배치 사이즈  
hist = model.fit(train_x, train_y, 
                 batch_size=batch_size, 
                 shuffle=True)    
```

**모델 적용시키기** 
```
hist = model.fit(train_x, train_y, 
                 batch_size=batch_size, 
                 shuffle=True)
```


## Evaluating 

모델 정확도 확인   
```
model.evaluate(test_x, test_y, batch_size=batch_size)
>  - loss: 0.0240 - accuracy: 0.9845
```

## 테스트 해보기   

**모듈 임포트**    
```
import matplotlib.pyplot as plt
import numpy as np
%matplotlib inline
```

**이미지 데이터**     
7의 이미지 데이터 가져 옴 
```
test_image = test_x[0, :, :, 0] # 시각화 하기 위해 2개 디멘션으로 변경 
test_image.shape
>(28,28) 
```

**예측** 
모델에 적용할려면 다시 4개 디멘션으로 변경해야함   
(배치사이즈, 높이, 너비, 채널)     

```
pred = model.predict(test_image.reshape(1, 28, 28, 1)) #reshape 활용 디멘션 추가  
pred.shape # 예측값 1행 10열 
> (1,10) 
pred # 예측값 나열   
> array([[1.09256916e-07, 2.40960702e-07, 1.94845006e-06, 8.54221707e-06,
        6.82931267e-09, 1.55464846e-07, 1.07366676e-11, 9.99967813e-01,
        1.78844758e-07, 2.09996360e-05]], dtype=float32)
np.argmax(pred)
> 7 # 예측값을 7로 평가함. (정확)
```

## Test Batch 

배치 사이즈를 32로 해서 테스트해보기    
```
test_batch = test_x[:32]
test_batch.shape
> (32, 28, 28, 1)
preds = model.predict(test_batch)  # 결과 저장
```

```
np.argmax(preds, -1) # 예측값 중 가장 큰 값만 뽑아냄 (여기서 5번째가 4)
> array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6,
       6, 5, 4, 0, 7, 4, 0, 1, 3, 1], dtype=int64)
plt.imshow(test_batch[4, :, :, 0], 'gray') # 위에 최댓값들 중에서 5번째 인덱스 값의 결과를 출력   
plt.show()
> 4 이미지 출력 
```




