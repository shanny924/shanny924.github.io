---
layout: post
title: ' [딥러닝] #4 Tensorflow 이미지분석 '
category : [School]
tag: [딥러닝]
---

# Tensorflow 이미지분석  

## Overview 

모델 성능 향상에 필요한 방법들         

* Cutom 데이터 import 
직접 데이터 생성할 경우 같은 데이터셋이나 크기가 다를 경우 발생 (28 * 28, 32 * 32 ) -> 중간에 **시각화** 필수    
* 이미지 Augmentation 
* callbck 모듈 : 모델 학습 도중에 epoch 또는 step 단위로 어떤 이벤트를 일으키는 옵션   
* 모델 저장 및 로드       


## 데이터 준비   


**모듈 임포트**

```
import os # 데이터 로드에 가장 많이 사용되는 모듈
from glob import glob # 원하는 파일 선택 가능  
from PIL import Image # 이미지 처리 패키지 
```

**os 를 통한 데이터 확인**

```
os.listdir('경로') # 해당경로 파일 리스트 보여줌
os.getcwd() # 현재경로확인 가능 
os.listdir('dataset/mnist_png/training/0/') # 0번 클래스의 파일 목록 보여줌 
```

**glob 를 통한 특정 파일 불러오기**

```
glob('dataset/mnist_png/training/0/*.png') # 0번 폴더 안에 ~png 라는 이름을 가진 파일 다 불러옴    
data_path = glob('dataset/mnist_png/training/*/*.png') # 트레이닝 폴더 안의 모든 png 불러옴 
len(data_path) 
> 60000 (전체 데이터셋 6만개 불러와짐) 
```

**각 label 에 해당하는 데이터 갯수 확인**

```
lable_nums = os.listdir('dataset/mnist_png/training')
label_nums 
> ['0','1','2',...'10'] 

num_dataset = []

for lbl_n in label_nums:
  data_per_class = os.listdir('dataset/mnist_png/training/' + lbl_n)
  nums_dataset.append(len(data_per_class))
  nums_dataset
> [5923,6742,5958,6131,5842,....] 
```


**path 변수에 첫번째 데이터만 넣고 pilow 시각화 **    

```
path = data_paths[0]
path
> '..../training\\0\\1.png'
image_pil = image.open(path)
image = np.array(image_pil) # 시각화하기 위해 numpy로 변환
plt.imshow(image,'gray')
plt.show()
> 0 모양 나옴 
```
 
 **tensorflow 시각화**
 
 tensor 에 맞게 이미지 변환 
 ```
 gfile = tf.io.read_file(path) #읽기
 image = tf.io.decode_image(gfile) #디코드 
 image.shape
 > TensorShape ([28,28,1])
 ```
 
 **Label 얻기** 
 
 레이블 수정할 필요성이 있을 때를 위해 알아둬야 함    
 label 얻기 함수  
 
 ```
 def get_label(path):
  label = path.split('\\')[-2] # \\ 기준 스플릿 했을때 끝에서 2번째가 레이블 이름이었음  
  return int(label)
 ```
 
 **데이터 사이즈가 서로 다를 경우** 
 
반드시 데이터 사이즈가 같아야 하므로 확인 뒤 사이즈 똑같이 만드는 법 알아둬야 함   
일단 전체 이미지의 높이랑 너비를 다 구함 
```
from tqdm import tqdm_notebook # 진행상황표시바 

 image.shape
 > [28,28,1]
 h, w , c = image.shape # 각각 숫자를 높이,너비,채널에 할당 
 
 height = []
 width = []
 for path in tqdm_notebook(data_paths):
  image_pil = image.open(path) 
  image = np.array(image_pil) # 시각화
  h, w = image.shape
  
  heights.append(h)
  width.append(w)
```
 
그런 뒤에 맞는지 시각화로 확인 
보니까 높이랑 너비 똑같은 그래프로 나옴  -> 통과 ! 

![3](https://i.imgur.com/iRq1deH.png)

 
 
## Batch size 이해 

한번의 들어갈 데이터의 수를 정하는 것 ! 


이미지 불러오는 함수 생성 
```
data_paths = glob('dataset/cifar.train/*.png') # 모든 트레인 데이터 파일

def read_image(path):
  gfile = tf.io.read_file(path)
  image = tf.io.decode_image(gfile,dtype=tf.float32)
  return image 
image = read_image(data_paths[1])  # 두번째 이미지 데이터 
plt.imshow(image)
plt.show()
```

여러 이미지 불러오는 코드  
```
for i in range(8):  #8개 이미지 한번에 불러옴 
  plt.imshow(read_image(data_paths[i])))
  plt.show()
```

**Batch size** 

한 스텝마다 정한 배치사이즈만큼 들어가게 됨.   
전체 데이터가 다 들어가면 한 epoch 가 끝나게 됨.   

이 size 를 어떻게 구현하는가?    
똑같은 이미지가 들어가면 안됨. 랜덤, 셔플 등 다양한 방법이 있음   

! [4](https://i.imgur.com/95k9sli.png)
이렇게 8개의 이미지를 어펜드해서 하나의 리스트로 묶어버린 다음 텐서로 변환하는 것     
그러면 batch_image size 가 변해있음 

```
batch = tf.convert_to_tensor(batch_image) # 배치이미지리스트를 텐서로 변환
batch.shape
> TensorShape([8,32,32,3]) # 배치 사이즈가 8로 바뀌어있음 !! 
```

**함수로 정의**

```
def make_batch(batch_paths):
  batch_images = []

  for path in batch_paths:
    image = read_image(path)
    batch_Images.append(image)
  return tf.convert_to_tensor(batch_images)

batch_images = make_batch(data_paths[:8]) #data path 경로에 있는 파일 중 8개를 배치 사이즈로 만듦. 
```


# Image Data generation 

keras 제공 이미지 데이터 학습 위한 라이브러리 (자주 사용) 
오브젝트의 크기나 회전 각도에 따라 예측 값이 달라지지 않도록 랜덤으로 변형한 학습 데이터    
**성능 향상과 오버피팅 방지** 에 기여함   

## 모듈 임포트 

```
from tensorflow.keras.preprocessing.image import ImageDateGenerator 
```

## 모델에 넣기 위해 차원 추가 

```
image.shape
> TensorShape([28,28,1])
inputs = image[tf.newaxis,...] # 축 추가
input.shpae
> TensorShape([1,28,28,1])
```

## 변형된 이미지 제네레이션  

```
datagen = ImageDataGenerator(
  rotation_range = 20,  #회전 
  width_shift_range = 0.5 #너비 
  height_shift_range = 0.5 #높이 
  horizontal_flip = True  #수평 뒤집기 
  
result = next(iter(datagen.flow(inputs))) # 변환된 이미지 랜덤으로 추출 
plt.imshow(result[0, :, :, 0], 'gray')   # 시각화를 위해 차원 축소 
plt.show()  # 실행할때마다 변형된 이미지 랜덤 추출됨 
```


## Rescale 시 주의사항 

**학습 데이터랑 테스트 데이터에 똑같이 나눠줘야 함 !**
똑같이 하지 않으면 에러가 남

![5](https://i.imgur.com/29rDZw6.png)

augmentation 의 경우에는 학습 데이터에만 주면 됨   




## Image Data generation CNN 에 적용 

임포트과정 생략   

**하이퍼파라미터 튜닝**
```
num_epochs = 10
batch_size = 32
learning_rate = 0.001
dropout_rate = 0.5
input_shape = (28, 28, 1)
num_classes = 10
```
**데이터 프로세스**

리스케일 & 어그멘테이션 
```
train_datagen = ImageDataGenerator(
        rescale=1./255,
        width_shift_range=0.3,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)  # 무조건 같이 리스케일링 해줘야함 ! 
```

위에서 만든 변형된 데이터를 집어넣음  
```
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=input_shape[:2], # 채널 무시하고 28*28 만 고려 
        batch_size=batch_size,
        color_mode='grayscale',
        class_mode='categorical'     # 클래스 10개이므로 categorical (not binary)
)

validation_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=input_shape[:2], # 채널 - (28,28까지)
        batch_size=batch_size,
        color_mode='grayscale',
        class_mode='categorical'
)
```

**모델 빌드**

달라진 게 없음 ! 
```
inputs = layers.Input(input_shape)
net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)
net = layers.Activation('relu')(net)
net = layers.Conv2D(32, (3, 3), padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPooling2D(pool_size=(2, 2))(net)
net = layers.Dropout(dropout_rate)(net)

net = layers.Conv2D(64, (3, 3), padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.Conv2D(64, (3, 3), padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPooling2D(pool_size=(2, 2))(net)
net = layers.Dropout(dropout_rate)(net)

net = layers.Flatten()(net)
net = layers.Dense(512)(net)
net = layers.Activation('relu')(net)
net = layers.Dropout(dropout_rate)(net)
net = layers.Dense(num_classes)(net)
net = layers.Activation('softmax')(net)

model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')
```
**컴파일**

```
# Model is the full model w/o custom layers
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization
              loss='categorical_crossentropy',  # Loss Function 
              metrics=['accuracy'])  # Metrics / Accuracy
```

**트레이닝**

모델에 핏 시켜보고 정확도 확인 
```
model.fit_generator(
        train_generator,
        steps_per_epoch=len(train_generator),
        epochs=num_epochs,
        validation_data=validation_generator,
        validation_steps=len(validation_generator))
> ...
Epoch 10/10
1875/1875 [==============================] - 237s 127ms/step - loss: 0.1162 - accuracy: 0.9647 - val_loss: 0.0352 - val_accuracy: 0.9876
```










